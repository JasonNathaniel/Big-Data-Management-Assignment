{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fa247700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statement\n",
    "import json\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pprint import pprint\n",
    "import geohash2 as pgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ba7dd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark context\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master('local[*]')\n",
    "    .appName('Streaming Assignment part B Data')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "000ff59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'partB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ca806518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create streaming context\n",
    "kafka_sdf = (\n",
    "    spark.readStream\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', 'localhost:9092')\n",
    "    .option('subscribe', topic)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "01996aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "partB_sdf = kafka_sdf.select('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4918e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df, batch_id):\n",
    "    \n",
    "    # this is in list form \n",
    "    raw_data = batch_df.collect()\n",
    "   \n",
    "    dataList =[]\n",
    "    \n",
    "    # change the datatype in raw_data into json form\n",
    "    if len(raw_data) > 0:\n",
    "        \n",
    "        for data in raw_data : \n",
    "            data = data.value\n",
    "            data = data.decode('utf-8')\n",
    "            data = json.loads(data)\n",
    "            dataList.append(data)\n",
    "              \n",
    "    raw_data = dataList\n",
    "\n",
    "    climate = []\n",
    "    hotspot= []\n",
    "    \n",
    "    # divide the data in raw_data into climate data and hotspot data \n",
    "    for data in raw_data : \n",
    "        # for producer 1, it is climate data\n",
    "        if data['producer'] == 1:\n",
    "            climate.append(data)\n",
    "        # for producer 2 and 3, it is hotspot data\n",
    "        else : \n",
    "            hotspot.append(data)\n",
    "    \n",
    "    # if there is no climate data, return \n",
    "    if len(climate) == 0 :\n",
    "        return\n",
    "    \n",
    "    # there could only be one climate data in a 10 second interval\n",
    "    climate = climate[0]\n",
    "    \n",
    "    # compute geo hash for climate data\n",
    "    climateGeoVal = pgh.encode(climate['latitude'], climate['longitude'], precision = 3)\n",
    "    \n",
    "    tempHotspot = []\n",
    "    \n",
    "    # compute geohash for each hotspot data and get the hotspot data that has the same geo hash value as climate data\n",
    "    for data in hotspot :\n",
    "        geoVal = pgh.encode(data['latitude'], data['longitude'], precision = 3)\n",
    "    \n",
    "        if geoVal == climateGeoVal : \n",
    "            tempHotspot.append(data)\n",
    "            \n",
    "    # now hotpost is a list that contain hotspot data with the same geo hash value as climate data\n",
    "    hotspot = tempHotspot    \n",
    "    \n",
    "    # if there is no hotspot data that has the same location as climate, insert the climate data to mongodb\n",
    "    if len(hotspot) == 0 : \n",
    "        \n",
    "        # connect with mongodb and get the database\n",
    "        client = MongoClient() \n",
    "        db = client.fit3182_assignment_db\n",
    "        climate['hotspot'] = []\n",
    "        db.partB.insert_one(climate)\n",
    "        return \n",
    "    \n",
    "    GHValues = []\n",
    "    GHValuesUniq = []\n",
    "    \n",
    "    # get the geohash value of each data in hotspot\n",
    "    for data in hotspot : \n",
    "        geoVal = pgh.encode(data['latitude'], data['longitude'], precision = 5)\n",
    "        GHValues.append(geoVal)\n",
    "        \n",
    "        # get unique geo hash value\n",
    "        if geoVal not in GHValuesUniq : \n",
    "            GHValuesUniq.append(geoVal)\n",
    "    \n",
    "    hotspotFinal = []\n",
    "    \n",
    "    # now, group the hotspot data by location and get the average value for surface temperature and confidence\n",
    "    # for each unique geohash value\n",
    "    for value in GHValuesUniq : \n",
    "        \n",
    "        hotspotGroup = []\n",
    "        \n",
    "        # get the hotspot data that has the same geo hash value\n",
    "        for i in range(len(GHValues)) : \n",
    "            if GHValues[i] == value : \n",
    "                hotspotGroup.append(hotspot[i])\n",
    "                \n",
    "        surfaceTemps = []\n",
    "        confidences = []\n",
    "        \n",
    "        # get their surface temperatures and confidences\n",
    "        for data in hotspotGroup : \n",
    "            surfaceTemps.append(data['surface_temperature_celcius'])\n",
    "            confidences.append(data['confidence'])\n",
    "\n",
    "        # calculate mean for surface temperature and confidences\n",
    "        meanSurfaceTemp = sum(surfaceTemps) / len(surfaceTemps)\n",
    "        meanConfidence = sum(confidences) / len(confidences)\n",
    "        \n",
    "        data = hotspotGroup[0]\n",
    "        data['surface_temperature_celcius'] = meanSurfaceTemp\n",
    "        data['confidence'] = meanConfidence \n",
    "        data['date'] = climate['date']\n",
    "        \n",
    "        hotspotFinal.append(data)\n",
    "        \n",
    "\n",
    "    # detect the cause of fire\n",
    "    if climate['air_temperature_celcius'] > 20 and climate['GHI_w/m2'] > 180 : \n",
    "        climate['fire_cause'] = 'natural'\n",
    "    else :\n",
    "        climate['fire_cause'] = 'other'\n",
    "    \n",
    "    # embedded the hotspotFinal array into the climate data\n",
    "    climate['hotspot'] = hotspotFinal\n",
    "    \n",
    "    # store climate and embedded hotspot data to mongodb  \n",
    "    client = MongoClient() \n",
    "    db = client.fit3182_assignment_db\n",
    "    db.partB.insert_one(climate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "27c5cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = (\n",
    "    partB_sdf\n",
    "    .writeStream\n",
    "    .outputMode('append')\n",
    "    .trigger(processingTime='10 seconds')\n",
    "    .foreachBatch(process_batch)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2f772131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/student/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/student/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted by CTRL-C. Stopping query.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    query = writer.start()\n",
    "    query.awaitTermination()\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted by CTRL-C. Stopping query.')\n",
    "except StreamingQueryException as exc:\n",
    "    print(exc)\n",
    "finally:\n",
    "    query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080fc29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
